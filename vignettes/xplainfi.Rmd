---
title: "xplainfi"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{xplainfi}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
set.seed(123)
# Quiet down
lgr::get_logger("mlr3")$set_threshold("warn")
```

```{r setup}
library(xplainfi)

# learners, tasks, etc.
library(mlr3)
library(mlr3learners)
```

Defining a simple example case:

- Breast cancer task
- Random forests with 100 trees
- Holdout split (default)
- Measure: Brier score

```{r setup-problem}
task <- tsk("breast_cancer")
learner <- lrn("classif.ranger", predict_type = "prob")
measure <- msr("classif.bbrier")
```

## PFI

### Simple case without resampling

Default behavior will internally construct standard holdout resampling with default ratio

Calculating PFI: 

```{r}
pfi <- PFI$new(
  task = task,
  learner = learner,
  measure = measure
)

# Stores parameter set to calculate PFI in different ways
pfi$param_set

# Default behavior should be sane
pfi$compute()
```

Q: Should `$compute()` be run on construction? Between the call to `$new()` and `$compute()` there's nothing that needs to happen technically, as long as the `relation` param could be set directly.

Does not recompute if not needed, as `"difference"` is the default:

```{r}
pfi$compute(relation = "difference")
```

Recomputes if param changes, stores new param

```{r}
pfi$compute(relation = "ratio")
pfi$param_set
```

Q: When `$compute()` is called again its default value for `"relation"` (i.e. `"difference"`) is used, which doesn't seem ideal.
Maybe this default should be the param stored in the object itself rather than feel like a separate function.

```{r}
pfi$compute()
```

Retrieve aggregated scores manually:

```{r}
pfi$importance
```

### With resampling

```{r}
learner <- lrn("classif.ranger", predict_type = "prob")
resampling <- rsmp("cv", folds = 3)
measure <- msr("classif.bbrier")

pfi <- PFI$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = measure
)

pfi$resampling
pfi$resample_result

pfi$compute()

pfi$resample_result

pfi$importance
```

Different measure:  

Q: Maybe it would be worth allowing to change measure post-hoc?

```{r}
pfi <- PFI$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = msr("classif.auc")
)

pfi$compute(relation = "ratio")
pfi$compute(relation = "difference")
```

### With multiple permutation iterations

```{r}
pfi <- PFI$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = msr("classif.ce"),
  iters_perm = 5 # permute each feature 5 times in each resampling iteration
)

pfi$compute(relation = "ratio")
```


## LOCO

Same setup but now using LOCO, which differs in that it internally needs to refit the model.  
Notably, the `Task` object does not need to be modified, as it suffices to adjust the `.$col_roles$feature` property.

```{r}
learner <- lrn("classif.ranger", predict_type = "prob")

loco <- LOCO$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = msr("classif.bbrier")
)

loco$compute(relation = "ratio")

loco$scores
```

## Aggregating results

Not sure if there should be a "blessed" way of combining results like this, ideally it should not be possible to lose track of which score refers to which measure

```{r}
importance_combined <- merge(
  pfi$importance,
  loco$importance,
  by = "feature"
)

data.table::setnames(
  importance_combined,
  old = c("importance.x", "importance.y"),
  new = c("pfi", "loco")
)

importance_combined |>
  knitr::kable(digits = 4, caption = "Importance scores (ratio)")
```


```{r}
library(ggplot2)

importance_combined |>
  data.table::melt(
    id.vars = "feature",
    value.name = "score",
    variable.name = "method"
  ) |>
  ggplot(aes(x = score, y = feature, color = method, fill = method)) +
  geom_col(position = "dodge", alpha = .5) +
  scale_color_brewer(palette = "Dark2", aesthetics = c("color", "fill")) +
  labs(
    title = "Feature Importance Scores",
    subtitle = sprintf(
      "For task %s and measure %s, using relativ scores",
      task$id,
      measure$id
    ),
    x = "Score",
    y = "Feature",
    color = "Method",
    fill = "Method",
    caption = sprintf("Using %i-fold %s", resampling$iters, resampling$id)
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title.position = "plot"
  )
```
