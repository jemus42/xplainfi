---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
# Quiet down
lgr::get_logger("mlr3")$set_threshold("warn")
options("xplain.progress" = interactive())
set.seed(123)
```

# `xplainfi`

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![R-CMD-check](https://github.com/jemus42/xplainfi/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/jemus42/xplainfi/actions/workflows/R-CMD-check.yaml)
[![codecov](https://codecov.io/gh/jemus42/xplainfi/graph/badge.svg?token=QIQDMP3AM7)](https://codecov.io/gh/jemus42/xplainfi)
<!-- badges: end -->

The goal of `xplainfi` is to collect common feature importance methods under a unified and extensible interface.  

It is built around [mlr3](https://mlr-org.com/) as available abstractions for learners, tasks, measures, etc. greatly simplify the implementation of importance measures.

## Installation

You can install the development version of `xplainfi` like so:

``` r
# install.packages(pak)
pak::pak("jemus42/xplainfi")
```

## Example: PFI

Here is a basic example on how to calculate PFI for a given learner and task, using repeated cross-validation as resampling strategy and computing PFI within each resampling 5 times on the `friedman1` task (see `?mlbench::mlbench.friedman1`).

The `friedman1` task has the following structure:

$$y = 10 \sin(\pi x_1 x_2) + 20(x_3 - 0.5)^2 + 10x_4 + 5x_5 + \varepsilon$$

Where $x_{1,2,3,4,5}$ are named `important1` through `important5` in the `Task`, with additional numbered `unimportant` features without effect on $y$.

```{r setup}
library(xplainfi)
library(mlr3learners)

task = tgen("friedman1")$generate(1000)
learner = lrn("regr.ranger", num.trees = 100)
measure = msr("regr.mse")

pfi = PFI$new(
  task = task,
  learner = learner,
  measure = measure,
  resampling = rsmp("cv", folds = 3),
  iters_perm = 5
)
```

Compute and print PFI scores:

```{r pfi-compute}
pfi$compute()
```

Retrieve scores later in `pfi$importance`.

When PFI is computed based on resampling with multiple iterations, and / or multiple permutation iterations, the individual scores can be retrieved as a `data.table`:

```{r pfi-scores}
str(pfi$scores)
```

Where `iter_rsmp` corresponds to the resampling iteration, i.e., 3 for 3-fold cross-validation, and `iter_perm` corresponds to the permutation iteration within each resampling iteration, 5 in this case.
While `pfi$importance` contains the means and standard deviations across all iterations, `pfi$scores` allows you to manually aggregate them in any way you see fit.

This of course also enables visualization across iterations:

```{r pfi-plot}
#| fig-width: 6
#| fig-height: 5
library(ggplot2)

ggplot(pfi$scores, aes(x = importance, y = reorder(feature, importance))) +
  geom_boxplot() +
  labs(
    title = "PFI Scores on Friedman1",
    subtitle = "Aggregated over 3-fold CV with 5 permutations per iteration",
    x = "Importance",
    y = "Feature"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title.position = "plot",
    panel.grid.major.y = element_blank()
  )
```

If the measure in question needs to be maximized ratehr than minimized (like $R^2$), the internal importance calculation takes that into account via the `$minimize` property of the measure object and calculates importances such that the "performance improvement" -> higher importance score holds:

```{r pfi-rsq}
pfi = PFI$new(
  task = task,
  learner = learner,
  measure = msr("regr.rsq"),
  iters_perm = 1
)

pfi$compute()
```
