[{"path":"https://jemus42.github.io/xplainfi/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 xplainfi authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/loco-loci.html","id":"leave-one-covariate-out-loco","dir":"Articles","previous_headings":"","what":"Leave-One-Covariate-Out (LOCO)","title":"LOCO and LOCI","text":"LOCO measures feature importance comparing model performance without feature. feature, learner retrained without feature performance difference indicates feature‚Äôs importance. feature jj, LOCO calculated difference expected loss model fit without feature full model: LOCOj=ùîº(L(Y,f‚àíj(X‚àíj)))‚àíùîº(L(Y,f(X)))\\text{LOCO}_j = \\mathbb{E}(L(Y, f_{-j}(X_{-j}))) - \\mathbb{E}(L(Y, f(X))) Higher values indicate important features (larger performance drop removed).","code":"task <- tgen(\"friedman1\")$generate(n = 200) learner <- lrn(\"regr.lm\") measure <- msr(\"regr.mse\")  loco <- LOCO$new(   task = task,   learner = learner,   measure = measure )  loco$compute() #> Key: <feature> #>          feature   importance #>           <char>        <num> #>  1:   important1  1.907472683 #>  2:   important2  4.344817068 #>  3:   important3 -0.038993051 #>  4:   important4  9.868411131 #>  5:   important5  2.159374339 #>  6: unimportant1  0.050115133 #>  7: unimportant2 -0.019501906 #>  8: unimportant3  0.106014948 #>  9: unimportant4  0.005096387 #> 10: unimportant5  0.024761713"},{"path":"https://jemus42.github.io/xplainfi/articles/loco-loci.html","id":"leave-one-covariate-in-loci","dir":"Articles","previous_headings":"","what":"Leave-One-Covariate-In (LOCI)","title":"LOCO and LOCI","text":"LOCI measures feature importance training models individual feature comparing performance featureless (baseline) model. shows much predictive power feature provides , beyond optimal constant prediction. feature jj, LOCI calculated difference expected loss featureless learner constant model model including feature: LOCIj=ùîº(L(Y,f‚àÖ))‚àíùîº(L(Y,fj(Xj)))\\text{LOCI}_j = \\mathbb{E}(L(Y, f_{\\emptyset})) - \\mathbb{E}(L(Y, f_j(X_{j}))) Higher values indicate important features (better individual performance compared baseline).","code":"loci <- LOCI$new(   task = task,   learner = learner,   measure = measure )  loci$compute() #> Key: <feature> #>          feature  importance #>           <char>       <num> #>  1:   important1  0.24301370 #>  2:   important2  2.00562769 #>  3:   important3 -0.24969927 #>  4:   important4  5.15158778 #>  5:   important5  1.94506889 #>  6: unimportant1 -0.02398509 #>  7: unimportant2  0.08193745 #>  8: unimportant3  0.37764092 #>  9: unimportant4  0.24828048 #> 10: unimportant5  0.16518286"},{"path":"https://jemus42.github.io/xplainfi/articles/loco-loci.html","id":"multiple-refits","dir":"Articles","previous_headings":"","what":"Multiple Refits","title":"LOCO and LOCI","text":"Like PFI iters_perm multiple permutation iterations, LOCO LOCI support iters_refit multiple refit iterations per resampling iteration: LOCO scores per refit resampling fold","code":"loco_multi = LOCO$new(   task = task,   learner = learner,   measure = measure,   resampling = rsmp(\"cv\", folds = 3),   iters_refit = 3L )  loco_multi$compute() #> Key: <feature> #>          feature  importance #>           <char>       <num> #>  1:   important1  2.63847146 #>  2:   important2  6.32614881 #>  3:   important3 -0.02421940 #>  4:   important4  8.23092916 #>  5:   important5  1.87820513 #>  6: unimportant1  0.04498329 #>  7: unimportant2 -0.08772072 #>  8: unimportant3  0.04221687 #>  9: unimportant4 -0.26932117 #> 10: unimportant5 -0.07450104  # Check individual scores with multiple refits loco_multi$scores[1:10, ] |>   knitr::kable(digits = 4, caption = \"LOCO scores per refit and resampling fold\")"},{"path":"https://jemus42.github.io/xplainfi/articles/loco-loci.html","id":"comparing-loco-and-loci","dir":"Articles","previous_headings":"","what":"Comparing LOCO and LOCI","title":"LOCO and LOCI","text":"LOCO vs LOCI importance scores Interpreting results: LOCO: Higher values indicate important features (larger performance drop removed) Positive values: feature performs better featureless baseline Negative values: feature performs worse featureless baseline","code":"# Combine results for comparison importance_combined <- rbind(   loco$importance[, method := \"LOCO\"],   loci$importance[, method := \"LOCI\"] )  importance_combined <- importance_combined |>   dcast(feature ~ method, value.var = \"importance\")  importance_combined |>   knitr::kable(digits = 4, caption = \"LOCO vs LOCI importance scores\") importance_combined |>   data.table::melt(     id.vars = \"feature\",     value.name = \"score\",     variable.name = \"method\"   ) |>   ggplot(aes(x = score, y = reorder(feature, score), color = method, fill = method)) +   facet_wrap(vars(method), ncol = 1, scales = \"free\") +   geom_col(position = \"dodge\", alpha = 0.7) +   scale_color_brewer(palette = \"Set1\", aesthetics = c(\"color\", \"fill\")) +   labs(     title = \"LOCO vs LOCI Feature Importance\",     x = \"Importance Score\",     y = \"Feature\",     color = \"Method\",     fill = \"Method\"   ) +   theme_minimal(base_size = 14) +   theme(     legend.position = \"bottom\",     plot.title.position = \"plot\"   )"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"problem-setup-friedman1-task","dir":"Articles","previous_headings":"","what":"Problem Setup: Friedman1 Task","title":"Perturbation-based Feature Importance Methods","text":"‚Äôll use Friedman1 task generator provides ideal setup demonstrating feature importance methods. synthetic regression task known ground truth: 5 important features (important1 important5) actually affect target 5 unimportant features (unimportant1 unimportant5) pure noise target function : y=10*sin(œÄ*x1*x2)+20*(x3‚àí0.5)2+10*x4+5*x5+œµy = 10 * \\operatorname{sin}(\\pi * x_1 * x_2) + 20 * (x_3 - 0.5)^2 + 10 * x_4 + 5 * x_5 + \\epsilon makes easy evaluate whether importance methods correctly identify truly important features. task 400 observations 10 features: important1, important2, important3, important4, important5, unimportant1, unimportant2, unimportant3, unimportant4, unimportant5. target variable y.","code":"# Generate the task task <- tgen(\"friedman1\")$generate(n = 400) learner <- lrn(\"regr.ranger\", num.trees = 100) resampling <- rsmp(\"cv\", folds = 3) measure <- msr(\"regr.mse\")"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"permutation-feature-importance-pfi","dir":"Articles","previous_headings":"","what":"Permutation Feature Importance (PFI)","title":"Perturbation-based Feature Importance Methods","text":"PFI shuffles feature independently, breaking association feature target preserving marginal distribution. stable results, use: 3-fold CV reliable performance estimates Within resampling iteration, repeat permutation-prediction-scoring step iters_perm times Sample PFI detailed scores","code":"pfi <- PFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   iters_perm = 5 )  # Compute importance scores pfi_results <- pfi$compute(relation = \"difference\") pfi_results #> Key: <feature> #>          feature  importance #>           <char>       <num> #>  1:   important1  5.86554439 #>  2:   important2  7.53042540 #>  3:   important3  0.62852245 #>  4:   important4 12.07781769 #>  5:   important5  1.42191247 #>  6: unimportant1  0.03241761 #>  7: unimportant2  0.06147252 #>  8: unimportant3 -0.04262232 #>  9: unimportant4  0.07622793 #> 10: unimportant5 -0.01541102  # Also stored in pfi$importance #> Key: <feature> #>          feature  importance #>           <char>       <num> #>  1:   important1  5.86554439 #>  2:   important2  7.53042540 #>  3:   important3  0.62852245 #>  4:   important4 12.07781769 #>  5:   important5  1.42191247 #>  6: unimportant1  0.03241761 #>  7: unimportant2  0.06147252 #>  8: unimportant3 -0.04262232 #>  9: unimportant4  0.07622793 #> 10: unimportant5 -0.01541102  # Show a sample of detailed scores head(pfi$scores, 10) |>   knitr::kable(digits = 4, caption = \"Sample of PFI detailed scores\")"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"conditional-feature-importance-cfi","dir":"Articles","previous_headings":"","what":"Conditional Feature Importance (CFI)","title":"Perturbation-based Feature Importance Methods","text":"CFI uses conditional sampling preserve joint distribution features perturbing feature interest. default use Adversarial Random Forests (ARF) conditional sampler internally. Original important1 values: 0.246, 0.786, 0.492, 0.668, 0.521 Sampled important1 values (conditioned important2): -0.152, 0.829, 0.16, 0.756, 0.74","code":"sampler = ARFSampler$new(   task = task,    arf_args = list(verbose = FALSE),   forde_args = list() ) #> Warning: executing %dopar% sequentially: no parallel backend registered  # Example sampling for 5 randomly chosen rows from the task sample_data <- task$data(rows = sample(task$nrow, size = 5)) sampled_result <- sampler$sample(   feature = \"important1\",    data = sample_data,    conditioning_features = \"important2\" ) cfi <- CFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   iters_perm = 5,   sampler = sampler )  # Compute importance scores cfi_results <- cfi$compute(relation = \"difference\") cfi_results #> Key: <feature> #>          feature   importance #>           <char>        <num> #>  1:   important1  3.174003832 #>  2:   important2  3.435560781 #>  3:   important3  0.487036933 #>  4:   important4  4.345208881 #>  5:   important5  0.551741678 #>  6: unimportant1  0.040457097 #>  7: unimportant2  0.055751318 #>  8: unimportant3 -0.036216862 #>  9: unimportant4  0.051101874 #> 10: unimportant5 -0.008660248"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"relative-feature-importance-rfi","dir":"Articles","previous_headings":"","what":"Relative Feature Importance (RFI)","title":"Perturbation-based Feature Importance Methods","text":"RFI conditions specific subset features, measuring importance relative features. Let‚Äôs condition two important features see others rank relative baseline.","code":"conditioning_set <- c(\"important1\", \"important2\")  rfi <- RFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   conditioning_set = conditioning_set,   iters_perm = 5,   sampler = sampler )  # Compute importance scores rfi_results <- rfi$compute(relation = \"difference\") rfi_results #> Key: <feature> #>          feature   importance #>           <char>        <num> #>  1:   important1  0.000000000 #>  2:   important2  0.000000000 #>  3:   important3  0.659032969 #>  4:   important4 11.168278482 #>  5:   important5  1.391927039 #>  6: unimportant1  0.035829586 #>  7: unimportant2  0.111951122 #>  8: unimportant3 -0.003414726 #>  9: unimportant4  0.063271393 #> 10: unimportant5  0.022609332"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"comparing-methods","dir":"Articles","previous_headings":"","what":"Comparing Methods","title":"Perturbation-based Feature Importance Methods","text":"Now let‚Äôs compare results three methods: Feature Importance Comparison (Difference Scores)","code":"# Combine results for comparison comparison <- merge(   pfi_results[, .(feature, pfi = importance)],   cfi_results[, .(feature, cfi = importance)],   by = \"feature\" ) comparison <- merge(   comparison,   rfi_results[, .(feature, rfi = importance)],   by = \"feature\" )  # Add feature type for analysis comparison[, feature_type := ifelse(grepl(\"^important\", feature), \"Important\", \"Noise\")]  comparison |>   knitr::kable(     digits = 4,      caption = \"Feature Importance Comparison (Difference Scores)\",     col.names = c(\"Feature\", \"PFI\", \"CFI\", \"RFI\", \"Type\")   )"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"visualization","dir":"Articles","previous_headings":"","what":"Visualization","title":"Perturbation-based Feature Importance Methods","text":"Let‚Äôs create comprehensive visualizations understand results:  Let‚Äôs also create correlation plot see similar methods :","code":"# Reshape data for plotting plot_data <- comparison |>   melt(     id.vars = c(\"feature\", \"feature_type\"),     measure.vars = c(\"pfi\", \"cfi\", \"rfi\"),     value.name = \"importance\",     variable.name = \"method\"   )  # Clean up method names plot_data[, method := toupper(method)]  # Create the comparison plot ggplot(plot_data, aes(x = importance, y = reorder(feature, importance), fill = method)) +   facet_wrap(~ feature_type, scales = \"free_y\", ncol = 1) +   geom_col(position = \"dodge\", alpha = 0.8) +   scale_fill_manual(values = c(\"PFI\" = \"steelblue\", \"CFI\" = \"darkgreen\", \"RFI\" = \"orange\")) +   labs(     title = \"Feature Importance Comparison: PFI vs CFI vs RFI\",     subtitle = glue::glue(\"Friedman1 task: 5 important + 5 noise features                           RFI conditioned on: {paste(conditioning_set, collapse = ', ')}\"),     x = \"Importance Score (Difference)\",     y = \"Feature\",     fill = \"Method\",     caption = glue::glue(\"Using {resampling$iters}-fold cross-validation                           and 5 permutation iterations\")   ) +   theme_minimal(base_size = 14) +   theme(     legend.position = \"bottom\",     plot.title.position = \"plot\"   ) # Calculate correlations between methods pfi_cfi_cor <- cor(comparison$pfi, comparison$cfi) pfi_rfi_cor <- cor(comparison$pfi, comparison$rfi) cfi_rfi_cor <- cor(comparison$cfi, comparison$rfi)  # Create correlation matrix plot cor_data <- comparison[, .(feature, pfi, cfi, rfi, feature_type)]  # PFI vs CFI p1 <- ggplot(cor_data, aes(x = pfi, y = cfi, color = feature_type)) +   geom_point(size = 3, alpha = 0.8) +   geom_smooth(method = \"lm\", se = FALSE, color = \"gray50\", linetype = \"dashed\") +   scale_color_manual(values = c(\"Important\" = \"steelblue\", \"Noise\" = \"lightcoral\")) +   labs(     title = \"PFI vs CFI\",     subtitle = sprintf(\"Correlation: %.3f\", pfi_cfi_cor),     x = \"PFI Score\", y = \"CFI Score\"   ) +   theme_minimal(base_size = 14) +   theme(legend.position = \"none\")  # PFI vs RFI   p2 <- ggplot(cor_data, aes(x = pfi, y = rfi, color = feature_type)) +   geom_point(size = 3, alpha = 0.8) +   geom_smooth(method = \"lm\", se = FALSE, color = \"gray50\", linetype = \"dashed\") +   scale_color_manual(values = c(\"Important\" = \"steelblue\", \"Noise\" = \"lightcoral\")) +   labs(     title = \"PFI vs RFI\",     subtitle = sprintf(\"Correlation: %.3f\", pfi_rfi_cor),     x = \"PFI Score\", y = \"RFI Score\"   ) +   theme_minimal(base_size = 14) +   theme(legend.position = \"none\")  # CFI vs RFI p3 <- ggplot(cor_data, aes(x = cfi, y = rfi, color = feature_type)) +   geom_point(size = 3, alpha = 0.8) +   geom_smooth(method = \"lm\", se = FALSE, color = \"gray50\", linetype = \"dashed\") +   scale_color_manual(     values = c(\"Important\" = \"steelblue\", \"Noise\" = \"lightcoral\"),     name = \"Feature Type\"   ) +   labs(     title = \"CFI vs RFI\",      subtitle = sprintf(\"Correlation: %.3f\", cfi_rfi_cor),     x = \"CFI Score\", y = \"RFI Score\"   ) +   theme_minimal(base_size = 14)  # Combine plots library(patchwork) (p1 / p2 / p3) +    plot_annotation(     title = \"Method Correlations\",     subtitle = \"Each point represents one feature\"   ) +   theme(legend.position = \"bottom\") #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"understanding-the-results","dir":"Articles","previous_headings":"","what":"Understanding the Results","title":"Perturbation-based Feature Importance Methods","text":"Let‚Äôs analyze well method distinguishes important noise features: Summary feature type","code":"# Calculate summary statistics by feature type summary_stats <- comparison[, .(   mean_importance = mean(c(pfi, cfi, rfi)),   pfi_mean = mean(pfi),   cfi_mean = mean(cfi),    rfi_mean = mean(rfi),   n_features = .N ), by = feature_type]  summary_stats |> knitr::kable(digits = 4, caption = \"Summary by feature type\") # Calculate separation ratios (how well each method separates signal from noise) important_pfi <- comparison[feature_type == \"Important\", mean(pfi)] noise_pfi <- comparison[feature_type == \"Noise\", mean(abs(pfi))] pfi_separation <- important_pfi / noise_pfi  important_cfi <- comparison[feature_type == \"Important\", mean(cfi)] noise_cfi <- comparison[feature_type == \"Noise\", mean(abs(cfi))] cfi_separation <- important_cfi / noise_cfi  important_rfi <- comparison[feature_type == \"Important\", mean(rfi)] noise_rfi <- comparison[feature_type == \"Noise\", mean(abs(rfi))] rfi_separation <- important_rfi / noise_rfi  # Store results for inline reporting pfi_sep <- round(pfi_separation, 2) cfi_sep <- round(cfi_separation, 2)  rfi_sep <- round(rfi_separation, 2) pfi_cfi <- round(pfi_cfi_cor, 3) pfi_rfi <- round(pfi_rfi_cor, 3) cfi_rfi <- round(cfi_rfi_cor, 3)"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"method-performance","dir":"Articles","previous_headings":"Understanding the Results","what":"Method Performance","title":"Perturbation-based Feature Importance Methods","text":"Separation ratios (well method distinguishes important noise features): - PFI: 120.64 - CFI: 62.41 - RFI: 55.76 Correlations methods: - PFI vs CFI: 0.98 - PFI vs RFI: 0.751 - CFI vs RFI: 0.619","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"understanding-the-differences","dir":"Articles","previous_headings":"","what":"Understanding the Differences","title":"Perturbation-based Feature Importance Methods","text":"three methods can yield different results make different assumptions: PFI assumes features independent measures marginal importance feature. CFI preserves conditional distribution P(X‚àíj|Xj)P(X_{-j} | X_j) perturbing feature jj, providing realistic assessment features correlated. RFI measures importance relative specific conditioning set, answering ‚Äúadditional information feature provide beyond already know conditioning features?‚Äù Friedman1 example: methods successfully identify important1 important5 important unimportant1 unimportant5 PFI treats feature isolation CFI accounts dependencies features RFI shows features add value beyond important1 important2","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"variability-analysis","dir":"Articles","previous_headings":"","what":"Variability Analysis","title":"Perturbation-based Feature Importance Methods","text":"Let‚Äôs examine stability importance estimates across resampling- permutation iterations using $scores tables:","code":"detailed_scores <- rbindlist(list(   pfi$scores[, method := \"PFI\"],   cfi$scores[, method := \"CFI\"],   rfi$scores[, method := \"RFI\"] ))  score_summary <- detailed_scores[, .(   mean_importance = mean(importance),   sd_importance = sd(importance),   n_iterations = .N ), by = .(feature, method)]  # Add feature type score_summary[, feature_type := ifelse(grepl(\"^important\", feature), \"Important\", \"Noise\")]  # Plot error bars ggplot(score_summary, aes(     y = reorder(feature, mean_importance),      x = mean_importance,     xmin = mean_importance - sd_importance,      xmax = mean_importance + sd_importance,     color = method)   ) +   facet_wrap(vars(feature_type), ncol = 1, scales = \"free_y\") +   geom_point(size = 3) +   geom_errorbarh(linewidth = 1, height = 0.3) +   scale_color_brewer(palette = \"Dark2\") +   labs(     title = \"Importance Score Variability: Mean ¬± SD\",     subtitle = glue::glue(\"Error bars show standard deviation across iterations                       RFI conditioned on: {paste(conditioning_set, collapse = ', ')}\"),     x = \"Score (Difference)\",     y = \"Feature\",     color = \"Method\",     caption = paste(\"Using\", resampling$iters, \"-fold CV and\", pfi$param_set$values$iters_perm, \"permutations each\")   ) +   theme_minimal(base_size = 14) +   theme(     plot.title.position = \"plot\",     legend.position = \"bottom\"   )"},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"custom-samplers","dir":"Articles","previous_headings":"Advanced Usage","what":"Custom Samplers","title":"Perturbation-based Feature Importance Methods","text":"can provide custom samplers control:","code":"# Create a custom ARF sampler with specific parameters custom_sampler <- ARFSampler$new(   task = task,   arf_args = list(num.trees = 50),  # Fewer trees for faster computation   forde_args = list(finite_bounds = \"no\") # Allow extrapolation )  cfi_custom <- CFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   sampler = custom_sampler )"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"empty-conditioning-set-for-rfi","dir":"Articles","previous_headings":"Advanced Usage","what":"Empty Conditioning Set for RFI","title":"Perturbation-based Feature Importance Methods","text":"RFI empty conditioning set produce similar results PFI: correlation PFI RFI empty conditioning set 0.997, confirming RFI(‚àÖ)‚âàPFI\\mathrm{RFI}(\\emptyset) \\approx \\mathrm{PFI} expected.","code":"rfi_empty <- RFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   conditioning_set = character(0), # Empty conditioning set   iters_perm = 5,   sampler = sampler )  rfi_empty_results <- rfi_empty$compute()  # Compare with PFI empty_comparison <- merge(   pfi_results[, .(feature, pfi = importance)],   rfi_empty_results[, .(feature, rfi_empty = importance)],   by = \"feature\" )  correlation_empty <- cor(empty_comparison$pfi, empty_comparison$rfi_empty)"},{"path":"https://jemus42.github.io/xplainfi/articles/perturbation-importance.html","id":"key-takeaways","dir":"Articles","previous_headings":"","what":"Key Takeaways","title":"Perturbation-based Feature Importance Methods","text":"methods correctly identify important features well-structured synthetic task PFI provides baseline marginal feature importance CFI accounts feature dependencies conditional sampling RFI measures relative importance beyond specified conditioning set Use PFI simple, interpretable marginal importance Use CFI feature dependencies matter Use RFI understand incremental value beyond known important features","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Shapley Additive Global Importance (SAGE)","text":"Shapley Additive Global Importance (SAGE) feature importance method based cooperative game theory uses Shapley values fairly distribute total prediction performance among features. Unlike permutation-based methods measure drop performance features perturbed, SAGE measures much feature contributes model‚Äôs overall performance marginalizing (removing) features. key insight SAGE provides complete decomposition model‚Äôs performance: sum SAGE values equals difference model‚Äôs performance performance features marginalized. xplainfi provides two implementations SAGE: MarginalSAGE: Marginalizes features independently (standard SAGE) ConditionalSAGE: Marginalizes features conditionally using ARF sampling","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"the-friedman1-task","dir":"Articles","previous_headings":"","what":"The Friedman1 Task","title":"Shapley Additive Global Importance (SAGE)","text":"‚Äôll use Friedman1 task generator demonstrate SAGE methods. synthetic regression task known ground truth makes easy interpret results: 5 important features (important1 important5) actually affect target 5 unimportant features (unimportant1 unimportant5) pure noise target function : y=10*sin(œÄ*x1*x2)+20*(x3‚àí0.5)2+10*x4+5*x5+œµy = 10 * \\operatorname{sin}(\\pi * x_1 * x_2) + 20 * (x_3 - 0.5)^2 + 10 * x_4 + 5 * x_5 + \\epsilon task 500 observations 10 features: important1, important2, important3, important4, important5, unimportant1, unimportant2, unimportant3, unimportant4, unimportant5. target variable y. Let‚Äôs set learner measure. ‚Äôll use random forest able capture nonlinear relationships data:","code":"set.seed(123) task = tgen(\"friedman1\")$generate(n = 500) learner = lrn(\"regr.ranger\", num.trees = 100) measure = msr(\"regr.mse\")"},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"marginal-sage","dir":"Articles","previous_headings":"","what":"Marginal SAGE","title":"Shapley Additive Global Importance (SAGE)","text":"Marginal SAGE marginalizes features independently averaging predictions reference dataset. standard SAGE implementation described original paper. Let‚Äôs visualize results:","code":"# Create Marginal SAGE instance marginal_sage = MarginalSAGE$new(   task = task,   learner = learner,   measure = measure,   n_permutations = 20L,  # More permutations for stable results   max_reference_size = 100L )  # Compute SAGE values marginal_sage$compute() #>          feature   importance #>           <char>        <num> #>  1:   important1  3.822106318 #>  2:   important2  4.772059968 #>  3:   important3  1.118253503 #>  4:   important4  5.893192811 #>  5:   important5  1.784793110 #>  6: unimportant1 -0.047656519 #>  7: unimportant2 -0.048262424 #>  8: unimportant3 -0.076914131 #>  9: unimportant4 -0.083675223 #> 10: unimportant5  0.004202781 print(marginal_sage$importance) #>          feature   importance #>           <char>        <num> #>  1:   important1  3.822106318 #>  2:   important2  4.772059968 #>  3:   important3  1.118253503 #>  4:   important4  5.893192811 #>  5:   important5  1.784793110 #>  6: unimportant1 -0.047656519 #>  7: unimportant2 -0.048262424 #>  8: unimportant3 -0.076914131 #>  9: unimportant4 -0.083675223 #> 10: unimportant5  0.004202781 # Extract importance scores marginal_results = marginal_sage$importance marginal_results$method = \"Marginal SAGE\"  # Create a factor with proper ordering marginal_results$feature = factor(   marginal_results$feature,   levels = marginal_results$feature[order(marginal_results$importance, decreasing = TRUE)] )  # Create bar plot ggplot(marginal_results, aes(x = feature, y = importance)) +   geom_col(aes(fill = grepl(\"^important\", feature)), alpha = 0.8) +   scale_fill_manual(     values = c(\"FALSE\" = \"lightcoral\", \"TRUE\" = \"steelblue\"),     labels = c(\"Noise features\", \"Important features\"),     name = \"Feature type\"   ) +   labs(     title = \"Marginal SAGE Feature Importance\",     subtitle = \"Friedman1 task: 5 important features + 5 noise features\",     x = \"Features\",      y = \"SAGE Value\"   ) +   theme_minimal(base_size = 14) +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"conditional-sage","dir":"Articles","previous_headings":"","what":"Conditional SAGE","title":"Shapley Additive Global Importance (SAGE)","text":"Conditional SAGE uses conditional sampling (via ARF default) marginalize features preserving dependencies remaining features. can provide different insights, especially features correlated. Let‚Äôs visualize conditional SAGE results:","code":"# Create Conditional SAGE instance conditional_sage = ConditionalSAGE$new(   task = task,   learner = learner,   measure = measure,   n_permutations = 20L,   max_reference_size = 100L ) #> Iteration: 0, Accuracy: 47.34% #> Warning: executing %dopar% sequentially: no parallel backend registered  # Compute SAGE values conditional_sage$compute() #>          feature  importance #>           <char>       <num> #>  1:   important1  4.66358094 #>  2:   important2  4.35406218 #>  3:   important3  1.24089600 #>  4:   important4  6.30771863 #>  5:   important5  1.50581856 #>  6: unimportant1  0.03857396 #>  7: unimportant2 -0.01510479 #>  8: unimportant3  0.01149043 #>  9: unimportant4  0.05352929 #> 10: unimportant5 -0.02463429 print(conditional_sage$importance) #>          feature  importance #>           <char>       <num> #>  1:   important1  4.66358094 #>  2:   important2  4.35406218 #>  3:   important3  1.24089600 #>  4:   important4  6.30771863 #>  5:   important5  1.50581856 #>  6: unimportant1  0.03857396 #>  7: unimportant2 -0.01510479 #>  8: unimportant3  0.01149043 #>  9: unimportant4  0.05352929 #> 10: unimportant5 -0.02463429 # Extract importance scores conditional_results = conditional_sage$importance conditional_results$method = \"Conditional SAGE\"  # Create a factor with proper ordering conditional_results$feature = factor(   conditional_results$feature,   levels = conditional_results$feature[order(conditional_results$importance, decreasing = TRUE)] )  # Create bar plot ggplot(conditional_results, aes(x = feature, y = importance)) +   geom_col(aes(fill = grepl(\"^important\", feature)), alpha = 0.8) +   scale_fill_manual(     values = c(\"FALSE\" = \"lightcoral\", \"TRUE\" = \"steelblue\"),     labels = c(\"Noise features\", \"Important features\"),     name = \"Feature type\"   ) +   labs(     title = \"Conditional SAGE Feature Importance\",     subtitle = \"Friedman1 task: 5 important features + 5 noise features\",     x = \"Features\",      y = \"SAGE Value\"   ) +   theme_minimal(base_size = 14) +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"comparison-of-methods","dir":"Articles","previous_headings":"","what":"Comparison of Methods","title":"Shapley Additive Global Importance (SAGE)","text":"Let‚Äôs compare two SAGE methods side side:  Let‚Äôs also create correlation plot see similar rankings :","code":"# Combine results combined_results = rbind(marginal_results, conditional_results)  # Create comparison plot ggplot(combined_results, aes(x = feature, y = importance, fill = method)) +   geom_col(position = \"dodge\", alpha = 0.8) +   scale_fill_manual(values = c(\"Marginal SAGE\" = \"steelblue\", \"Conditional SAGE\" = \"darkgreen\")) +   labs(     title = \"Marginal vs Conditional SAGE Comparison\",     subtitle = \"Friedman1 task: Both methods should identify important features\",     x = \"Features\",      y = \"SAGE Value\",     fill = \"Method\"   ) +   theme_minimal(base_size = 14) +   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +   facet_wrap(~ grepl(\"^important\", feature),               labeller = labeller(.default = function(x) ifelse(x, \"Important Features\", \"Noise Features\")),              scales = \"free_x\") # Merge the two results for correlation analysis merged_results = merge(   marginal_results[, c(\"feature\", \"importance\")],    conditional_results[, c(\"feature\", \"importance\")],    by = \"feature\",    suffixes = c(\"_marginal\", \"_conditional\") )  # Calculate correlation correlation = cor(merged_results$importance_marginal, merged_results$importance_conditional)  # Create scatter plot ggplot(merged_results, aes(x = importance_marginal, y = importance_conditional)) +   geom_point(aes(color = grepl(\"^important\", feature)), size = 3, alpha = 0.8) +   geom_smooth(method = \"lm\", se = FALSE, color = \"gray50\", linetype = \"dashed\") +   scale_color_manual(     values = c(\"FALSE\" = \"lightcoral\", \"TRUE\" = \"steelblue\"),     labels = c(\"Noise features\", \"Important features\"),     name = \"Feature type\"   ) +   labs(     title = \"Marginal vs Conditional SAGE Correlation\",     subtitle = sprintf(\"Pearson correlation: %.3f\", correlation),     x = \"Marginal SAGE Value\",     y = \"Conditional SAGE Value\"   ) +   theme_minimal(base_size = 14) +   geom_text(aes(label = feature), hjust = 0, vjust = -0.5, size = 3) #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"understanding-the-results","dir":"Articles","previous_headings":"","what":"Understanding the Results","title":"Shapley Additive Global Importance (SAGE)","text":"Let‚Äôs analyze learned comparison:","code":"# Calculate summary statistics important_marginal = marginal_results$importance[grepl(\"^important\", marginal_results$feature)] noise_marginal = marginal_results$importance[grepl(\"^unimportant\", marginal_results$feature)]  important_conditional = conditional_results$importance[grepl(\"^important\", conditional_results$feature)] noise_conditional = conditional_results$importance[grepl(\"^unimportant\", conditional_results$feature)]  # Store for inline reporting marg_imp_mean = round(mean(important_marginal), 4) marg_imp_std = round(sd(important_marginal), 4) marg_noise_mean = round(mean(noise_marginal), 4) marg_noise_std = round(sd(noise_marginal), 4) marg_separation = round(mean(important_marginal) / mean(abs(noise_marginal)), 2)  cond_imp_mean = round(mean(important_conditional), 4) cond_imp_std = round(sd(important_conditional), 4) cond_noise_mean = round(mean(noise_conditional), 4) cond_noise_std = round(sd(noise_conditional), 4) cond_separation = round(mean(important_conditional) / mean(abs(noise_conditional)), 2)  method_correlation = round(correlation, 3) total_sage_marginal = round(sum(marginal_results$importance), 4) total_sage_conditional = round(sum(conditional_results$importance), 4)"},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"marginal-sage-results","dir":"Articles","previous_headings":"Understanding the Results","what":"Marginal SAGE Results","title":"Shapley Additive Global Importance (SAGE)","text":"Important features - Mean: 3.4781 | Std: 2.0038 Noise features - Mean: -0.0505 | Std: 0.0347 Separation ratio: 66.7","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"conditional-sage-results","dir":"Articles","previous_headings":"Understanding the Results","what":"Conditional SAGE Results","title":"Shapley Additive Global Importance (SAGE)","text":"Important features - Mean: 3.6144 | Std: 2.1784 Noise features - Mean: 0.0128 | Std: 0.0336 Separation ratio: 126.08","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/sage-methods.html","id":"method-comparison","dir":"Articles","previous_headings":"Understanding the Results","what":"Method Comparison","title":"Shapley Additive Global Importance (SAGE)","text":"Correlation methods: 0.99 Total SAGE sum (Marginal): 17.1381 Total SAGE sum (Conditional): 18.1359","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"core-concepts","dir":"Articles","previous_headings":"","what":"Core Concepts","title":"Getting Started with xplainfi","text":"Feature importance methods xplainfi answer different related questions: much feature contribute model performance? (Permutation Feature Importance) happens remove features retrain? (Leave-One-Covariate-) much feature contribute individually? (Leave-One-Covariate-) features depend ? (Conditional Relative methods) methods share common interface built mlr3, making easy use task, learner, measure, resampling strategy.","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"basic-example","dir":"Articles","previous_headings":"","what":"Basic Example","title":"Getting Started with xplainfi","text":"Let‚Äôs use Friedman1 task, provides ideal setup demonstrating feature importance methods known ground truth: task 300 observations 10 features. Features important1 important5 truly affect target, unimportant1 unimportant5 pure noise. ‚Äôll use random forest learner cross-validation stable estimates. target function : y=10*sin(œÄ*x1*x2)+20*(x3‚àí0.5)2+10*x4+5*x5+œµy = 10 * \\operatorname{sin}(\\pi * x_1 * x_2) + 20 * (x_3 - 0.5)^2 + 10 * x_4 + 5 * x_5 + \\epsilon","code":"task <- tgen(\"friedman1\")$generate(n = 300) learner <- lrn(\"regr.ranger\", num.trees = 100) measure <- msr(\"regr.mse\") resampling <- rsmp(\"cv\", folds = 3)"},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"permutation-feature-importance-pfi","dir":"Articles","previous_headings":"","what":"Permutation Feature Importance (PFI)","title":"Getting Started with xplainfi","text":"PFI straightforward method: feature, permute (shuffle) values measure much model performance deteriorates. important features cause larger performance drops shuffled. importance column shows performance difference feature permuted. Higher values indicate important features. stable estimates, can use multiple permutation iterations per resampling fold: can also use ratio instead difference importance calculation:","code":"pfi <- PFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling )  pfi_results <- pfi$compute() pfi_results #> Key: <feature> #>          feature   importance #>           <char>        <num> #>  1:   important1  4.858724892 #>  2:   important2  8.155693005 #>  3:   important3  1.109254345 #>  4:   important4 10.784727349 #>  5:   important5  2.395793708 #>  6: unimportant1  0.009618005 #>  7: unimportant2  0.080903445 #>  8: unimportant3  0.044057887 #>  9: unimportant4 -0.082032243 #> 10: unimportant5 -0.137666350 pfi_stable <- PFI$new(   task = task,   learner = learner,   measure = measure,   resampling = resampling,   iters_perm = 5 )  pfi_stable$compute() #> Key: <feature> #>          feature   importance #>           <char>        <num> #>  1:   important1  5.625322621 #>  2:   important2  9.609986341 #>  3:   important3  1.196388744 #>  4:   important4 12.648328883 #>  5:   important5  1.705056896 #>  6: unimportant1 -0.002597636 #>  7: unimportant2  0.108962283 #>  8: unimportant3  0.039131183 #>  9: unimportant4 -0.058408934 #> 10: unimportant5 -0.041202334 pfi_stable$compute(relation = \"ratio\") #> Key: <feature> #>          feature importance #>           <char>      <num> #>  1:   important1  1.9484469 #>  2:   important2  2.4425122 #>  3:   important3  1.2212920 #>  4:   important4  2.9619275 #>  5:   important5  1.3790643 #>  6: unimportant1  0.9862282 #>  7: unimportant2  1.0098376 #>  8: unimportant3  1.0227458 #>  9: unimportant4  1.0090616 #> 10: unimportant5  0.9909342"},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"feature-samplers","dir":"Articles","previous_headings":"","what":"Feature Samplers","title":"Getting Started with xplainfi","text":"advanced methods account feature dependencies, xplainfi provides different sampling strategies. PFI uses simple permutation (marginal sampling), conditional samplers can preserve feature relationships. Let‚Äôs demonstrate conditional sampling using Adversarial Random Forests, preserves relationships features sampling: Now ‚Äôll conditionally sample important1 feature given values important2 important3: Original values: 0.288, 0.788, 0.409, 0.883, 0.94 Conditionally sampled values: 0.48, 0.317, 0.427, 0.302, 0.608 Note sampled values respect conditional distribution given values important2 important3. conditional sampling essential methods like CFI RFI need preserve feature dependencies. See vignette(\"perturbation-importance\") detailed comparisons.","code":"arf_sampler <- ARFSampler$new(task) #> Iteration: 0, Accuracy: 47.13% #> Warning: executing %dopar% sequentially: no parallel backend registered  sample_data <- task$data(rows = 1:5) sample_data$important1 #> [1] 0.2875775 0.7883051 0.4089769 0.8830174 0.9404673 sampled_conditional <- arf_sampler$sample(   feature = \"important1\",    data = sample_data,   conditioning_features = c(\"important2\", \"important3\") )  sampled_conditional$important1 #> [1] 0.4796056 0.3169238 0.4274408 0.3023370 0.6075926"},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"when-to-use-each-method","dir":"Articles","previous_headings":"","what":"When to Use Each Method","title":"Getting Started with xplainfi","text":"Choose PFI : - want fast, simple importance estimates - Features relatively independent - need quick baseline assessment Choose LOCO : - want accurate importance estimates - Computational cost major concern - Features may correlated - want understand impact completely removing features Choose LOCI : - want understand individual feature contributions - ‚Äôre interested feature selection (negative LOCI scores suggest features remove) - want compare features meaningful baseline","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"advanced-features","dir":"Articles","previous_headings":"","what":"Advanced Features","title":"Getting Started with xplainfi","text":"xplainfi supports many advanced features robust importance estimation: Multiple resampling strategies: Cross-validation, bootstrap, custom splits Multiple permutation/refit iterations: stable estimates Feature grouping: Compute importance groups related features Different relation types: Difference vs.¬†ratio scoring Conditional sampling: Account feature dependencies (see vignette(\"perturbation-importance\")) SAGE methods: Shapley-based approaches (see vignette(\"sage-methods\"))","code":""},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"detailed-scoring-information","dir":"Articles","previous_headings":"","what":"Detailed Scoring Information","title":"Getting Started with xplainfi","text":"methods store detailed scoring information analysis. Let‚Äôs examine structure PFI‚Äôs detailed scores: Detailed PFI scores (first 10 rows) can also summarize scoring structure:","code":"head(pfi$scores, 10) |>   knitr::kable(digits = 4, caption = \"Detailed PFI scores (first 10 rows)\") pfi$scores[, .(   features = uniqueN(feature),   resampling_folds = uniqueN(iter_rsmp),    permutation_iters = uniqueN(iter_perm),   total_scores = .N )] #>    features resampling_folds permutation_iters total_scores #>       <int>            <int>             <int>        <int> #> 1:       10                3                 1           30"},{"path":"https://jemus42.github.io/xplainfi/articles/xplainfi.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Getting Started with xplainfi","text":"vignette covered basics feature importance xplainfi. advanced usage: vignette(\"perturbation-importance\"): Deep dive PFI, CFI, RFI methods conditional sampling vignette(\"loco-loci\"): Detailed examples LOCO LOCI methods vignette(\"sage-methods\"): SAGE-based Shapley value methods package documentation (?PFI, ?LOCO, ?LOCI) provides complete API references.","code":""},{"path":"https://jemus42.github.io/xplainfi/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lukas Burk. Author, maintainer.","code":""},{"path":"https://jemus42.github.io/xplainfi/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Burk L (2025). xplainfi: Feature Importance Methods Model Interpretability. R package version 0.0.0.9000, https://jemus42.github.io/xplainfi/.","code":"@Manual{,   title = {xplainfi: Feature Importance Methods for Model Interpretability},   author = {Lukas Burk},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://jemus42.github.io/xplainfi/}, }"},{"path":"https://jemus42.github.io/xplainfi/index.html","id":"xplainfi","dir":"","previous_headings":"","what":"Feature Importance Methods for Model Interpretability","title":"Feature Importance Methods for Model Interpretability","text":"goal xplainfi collect common feature importance methods unified extensible interface. now, built specifically around mlr3, available abstractions learners, tasks, measures, etc. greatly simplify implementation importance measures.","code":""},{"path":"https://jemus42.github.io/xplainfi/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Feature Importance Methods for Model Interpretability","text":"can install development version xplainfi like :","code":"# install.packages(pak) pak::pak(\"jemus42/xplainfi\")"},{"path":"https://jemus42.github.io/xplainfi/index.html","id":"example-pfi","dir":"","previous_headings":"","what":"Example: PFI","title":"Feature Importance Methods for Model Interpretability","text":"basic example calculate PFI given learner task, using repeated cross-validation resampling strategy computing PFI within resampling 5 times: Compute print PFI scores: Retrieve scores later pfi$importance. PFI computed based resampling multiple iterations, / multiple permutation iterations, individual scores can retrieved data.table: iter_rsmp corresponds resampling iteration, .e., 3 * 2 = 6 2 repeats 3-fold cross-validation, iter_perm corresponds permutation iteration, 5 case. pfi$importance contains means across iterations, pfi$scores allows manually aggregate way see fit. simplest case, run PFI single resampling iteration (holdout) single permutation iteration, pfi$importance contain values pfi$scores.","code":"library(xplainfi) library(mlr3) library(mlr3learners)  task = tsk(\"german_credit\") learner = lrn(\"classif.ranger\", num.trees = 100) measure = msr(\"classif.ce\")  pfi = PFI$new(   task = task,   learner = learner,   measure = measure,   resampling = rsmp(\"repeated_cv\", folds = 3, repeats = 2),   iters_perm = 5 ) pfi$compute() #> Key: <feature> #>                     feature    importance #>                      <char>         <num> #>  1:                     age  9.929091e-04 #>  2:                  amount  1.288294e-02 #>  3:          credit_history  1.218554e-02 #>  4:                duration  1.598605e-02 #>  5:     employment_duration  3.890717e-03 #>  6:          foreign_worker -1.202700e-03 #>  7:                 housing -8.016999e-04 #>  8:        installment_rate  3.599408e-03 #>  9:                     job -1.002799e-03 #> 10:          number_credits -2.402103e-03 #> 11:           other_debtors  5.898713e-03 #> 12: other_installment_plans -9.095922e-04 #> 13:           people_liable  5.994018e-07 #> 14:     personal_status_sex -1.807496e-03 #> 15:       present_residence  6.944070e-04 #> 16:                property  1.291111e-03 #> 17:                 purpose  2.486918e-03 #> 18:                 savings  1.819694e-02 #> 19:                  status  3.978829e-02 #> 20:               telephone  1.293209e-03 #>                     feature    importance pfi$scores #> Key: <feature, iter_rsmp> #>        feature iter_rsmp iter_perm classif.ce_orig classif.ce_perm   importance #>         <char>     <int>     <int>           <num>           <num>        <num> #>   1:       age         1         1       0.2095808       0.2305389  0.020958084 #>   2:       age         1         2       0.2095808       0.2335329  0.023952096 #>   3:       age         1         3       0.2095808       0.2275449  0.017964072 #>   4:       age         1         4       0.2095808       0.2215569  0.011976048 #>   5:       age         1         5       0.2095808       0.2155689  0.005988024 #>  ---                                                                            #> 596: telephone         6         1       0.2612613       0.2432432 -0.018018018 #> 597: telephone         6         2       0.2612613       0.2552553 -0.006006006 #> 598: telephone         6         3       0.2612613       0.2612613  0.000000000 #> 599: telephone         6         4       0.2612613       0.2522523 -0.009009009 #> 600: telephone         6         5       0.2612613       0.2402402 -0.021021021 pfi_single = PFI$new(   task = task,   learner = learner,   measure = measure )  pfi_single$compute() #> Key: <feature> #>                     feature   importance #>                      <char>        <num> #>  1:                     age  0.003003003 #>  2:                  amount  0.012012012 #>  3:          credit_history  0.024024024 #>  4:                duration  0.012012012 #>  5:     employment_duration  0.006006006 #>  6:          foreign_worker  0.000000000 #>  7:                 housing  0.006006006 #>  8:        installment_rate  0.024024024 #>  9:                     job -0.003003003 #> 10:          number_credits -0.003003003 #> 11:           other_debtors  0.012012012 #> 12: other_installment_plans  0.006006006 #> 13:           people_liable  0.009009009 #> 14:     personal_status_sex  0.003003003 #> 15:       present_residence  0.006006006 #> 16:                property  0.003003003 #> 17:                 purpose  0.015015015 #> 18:                 savings  0.003003003 #> 19:                  status  0.054054054 #> 20:               telephone -0.003003003 #>                     feature   importance pfi_single$scores #> Key: <feature, iter_rsmp> #>                     feature iter_rsmp iter_perm classif.ce_orig classif.ce_perm #>                      <char>     <int>     <int>           <num>           <num> #>  1:                     age         1         1       0.2732733       0.2762763 #>  2:                  amount         1         1       0.2732733       0.2852853 #>  3:          credit_history         1         1       0.2732733       0.2972973 #>  4:                duration         1         1       0.2732733       0.2852853 #>  5:     employment_duration         1         1       0.2732733       0.2792793 #>  6:          foreign_worker         1         1       0.2732733       0.2732733 #>  7:                 housing         1         1       0.2732733       0.2792793 #>  8:        installment_rate         1         1       0.2732733       0.2972973 #>  9:                     job         1         1       0.2732733       0.2702703 #> 10:          number_credits         1         1       0.2732733       0.2702703 #> 11:           other_debtors         1         1       0.2732733       0.2852853 #> 12: other_installment_plans         1         1       0.2732733       0.2792793 #> 13:           people_liable         1         1       0.2732733       0.2822823 #> 14:     personal_status_sex         1         1       0.2732733       0.2762763 #> 15:       present_residence         1         1       0.2732733       0.2792793 #> 16:                property         1         1       0.2732733       0.2762763 #> 17:                 purpose         1         1       0.2732733       0.2882883 #> 18:                 savings         1         1       0.2732733       0.2762763 #> 19:                  status         1         1       0.2732733       0.3273273 #> 20:               telephone         1         1       0.2732733       0.2702703 #>                     feature iter_rsmp iter_perm classif.ce_orig classif.ce_perm #>       importance #>            <num> #>  1:  0.003003003 #>  2:  0.012012012 #>  3:  0.024024024 #>  4:  0.012012012 #>  5:  0.006006006 #>  6:  0.000000000 #>  7:  0.006006006 #>  8:  0.024024024 #>  9: -0.003003003 #> 10: -0.003003003 #> 11:  0.012012012 #> 12:  0.006006006 #> 13:  0.009009009 #> 14:  0.003003003 #> 15:  0.006006006 #> 16:  0.003003003 #> 17:  0.015015015 #> 18:  0.003003003 #> 19:  0.054054054 #> 20: -0.003003003 #>       importance"},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"ARF-based Conditional Sampler ‚Äî ARFSampler","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"Implements conditional sampling using Adversarial Random Forests (ARF). ARF can handle mixed data types (continuous categorical) provides flexible conditional sampling modeling joint distribution.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"ARFSampler fits Adversarial Random Forest model task data, uses generate samples \\(P(X_j | X_{-j})\\) \\(X_j\\) feature interest \\(X_{-j}\\) conditioning features.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"Watson, S. D, Blesch, Kristin, Kapar, Jan, Wright, N. M (2023). ‚ÄúAdversarial Random Forests Density Estimation Generative Modeling.‚Äù Proceedings 26th International Conference Artificial Intelligence Statistics, 5357‚Äì5375. https://proceedings.mlr.press/v206/watson23a.html. Blesch, Kristin, Koenen, Niklas, Kapar, Jan, Golchian, Pegah, Burk, Lukas, Loecher, Markus, Wright, N. M (2025). ‚ÄúConditional Feature Importance Generative Modeling Using Adversarial Random Forests.‚Äù Proceedings AAAI Conference Artificial Intelligence, 39(15), 15596‚Äì15604. doi:10.1609/aaai.v39i15.33712 .","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"xplainfi::FeatureSampler -> xplainfi::ConditionalSampler -> ARFSampler","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"arf_model Adversarial Random Forest model psi Distribution parameters estimated ARF","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"ARFSampler$new() ARFSampler$sample() ARFSampler$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"Creates new instance ARFSampler class. fit ARF parallel, set arf_args = list(parallel = TRUE) register parallel backend (see arf::arf).","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"","code":"ARFSampler$new(task, arf_args = NULL, forde_args = NULL)"},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"task (mlr3::Task) Task sample arf_args, forde_args (list) Arguments passed arf::adversarial_rf arf::forde respectively.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"method-sample-","dir":"Reference","previous_headings":"","what":"Method sample()","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"Sample values feature(s) conditionally features using ARF","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"","code":"ARFSampler$sample(   feature,   data = self$task$data(),   conditioning_features = NULL,   n_synth = 1,   evidence_row_mode = \"separate\",   ... )"},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"feature (character) Feature(s) interest sample (can single multiple) data (data.table) Data containing conditioning features. Defaults $task$data(), typically dedicated test set provided. conditioning_features (character(n) | NULL) Features condition (default: features) n_synth (1) Number samples generate (per row evidence, evidence_row_mode = \"separate\"). See arf::forge(). evidence_row_mode (\"separate\") Produce n_synth sample per row evidence. See arf::forge() ... arguments passed arf::forge().","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"Modified copy input data feature(s) sampled conditionally","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"","code":"ARFSampler$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ARFSampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ARF-based Conditional Sampler ‚Äî ARFSampler","text":"","code":"library(mlr3) task = tgen(\"2dnormals\")$generate(n = 100) sampler = ARFSampler$new(task) #> Iteration: 0, Accuracy: 47.24% #> Warning: executing %dopar% sequentially: no parallel backend registered data = task$data() sampled_data = sampler$sample(\"x1\", data, conditioning_features = \"x2\")"},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Feature Importance ‚Äî CFI","title":"Conditional Feature Importance ‚Äî CFI","text":"Implementation CFI using modular sampling approach","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional Feature Importance ‚Äî CFI","text":"Blesch, Kristin, Koenen, Niklas, Kapar, Jan, Golchian, Pegah, Burk, Lukas, Loecher, Markus, Wright, N. M (2025). ‚ÄúConditional Feature Importance Generative Modeling Using Adversarial Random Forests.‚Äù Proceedings AAAI Conference Artificial Intelligence, 39(15), 15596‚Äì15604. doi:10.1609/aaai.v39i15.33712 .","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Conditional Feature Importance ‚Äî CFI","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::PerturbationImportance -> CFI","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Conditional Feature Importance ‚Äî CFI","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Conditional Feature Importance ‚Äî CFI","text":"CFI$new() CFI$compute() CFI$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Conditional Feature Importance ‚Äî CFI","text":"Creates new instance CFI class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Importance ‚Äî CFI","text":"","code":"CFI$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   iters_perm = 1L,   sampler = NULL )"},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Importance ‚Äî CFI","text":"task, learner, measure, resampling, features Passed PerturbationImportance. iters_perm (integer(1)) Number sampling iterations. sampler (ConditionalSampler) Optional custom sampler. Defaults instantiationg ARFSampler internally default parameters.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Conditional Feature Importance ‚Äî CFI","text":"Compute CFI scores","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Importance ‚Äî CFI","text":"","code":"CFI$compute(relation = c(\"difference\", \"ratio\"), store_backends = TRUE)"},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Importance ‚Äî CFI","text":"relation (character(1)) relate perturbed scores originals store_backends (logical(1)) Whether store backends","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Conditional Feature Importance ‚Äî CFI","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Importance ‚Äî CFI","text":"","code":"CFI$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Importance ‚Äî CFI","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/CFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Feature Importance ‚Äî CFI","text":"","code":"library(mlr3) task = tgen(\"2dnormals\")$generate(n = 100) cfi = CFI$new(   task = task,   learner = lrn(\"classif.ranger\", num.trees = 50, predict_type = \"prob\"),   measure = msr(\"classif.ce\") ) #> Iteration: 0, Accuracy: 51.01% #> Iteration: 1, Accuracy: 35.68% cfi$compute() #> Key: <feature> #>    feature importance #>     <char>      <num> #> 1:      x1 0.09090909 #> 2:      x2 0.18181818"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional SAGE ‚Äî ConditionalSAGE","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"SAGE conditional sampling (features marginalized conditionally). Uses ARF default conditional marginalization.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::SAGE -> ConditionalSAGE","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print() xplainfi::SAGE$compute()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"ConditionalSAGE$new() ConditionalSAGE$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"Creates new instance ConditionalSAGE class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"","code":"ConditionalSAGE$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   n_permutations = 10L,   reference_data = NULL,   sampler = NULL,   max_reference_size = 100L )"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"task, learner, measure, resampling, features Passed SAGE. n_permutations (integer(1)) Number permutations sample. reference_data (data.table) Optional reference dataset. sampler (ConditionalSampler) Optional custom sampler. Defaults ARFSampler. max_reference_size (integer(1)) Maximum size reference dataset.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"","code":"ConditionalSAGE$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSAGE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional SAGE ‚Äî ConditionalSAGE","text":"","code":"library(mlr3) task = tgen(\"friedman1\")$generate(n = 100) sage = ConditionalSAGE$new(   task = task,   learner = lrn(\"regr.ranger\", num.trees = 50),   measure = msr(\"regr.mse\"),   n_permutations = 3L ) #> Iteration: 0, Accuracy: 48.72% sage$compute() #>          feature  importance #>           <char>       <num> #>  1:   important1  2.43859740 #>  2:   important2  3.16250083 #>  3:   important3 -0.23409055 #>  4:   important4  4.07486299 #>  5:   important5  1.06578200 #>  6: unimportant1  0.27184491 #>  7: unimportant2  0.08221231 #>  8: unimportant3 -0.17193736 #>  9: unimportant4 -0.16713389 #> 10: unimportant5  0.13310937"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Feature Sampler ‚Äî ConditionalSampler","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"Base class conditional sampling methods features sampled conditionally features. abstract class extended concrete implementations.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"xplainfi::FeatureSampler -> ConditionalSampler","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"ConditionalSampler$new() ConditionalSampler$sample() ConditionalSampler$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"Creates new instance ConditionalSampler class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"","code":"ConditionalSampler$new(task)"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"task (mlr3::Task) Task sample ","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"method-sample-","dir":"Reference","previous_headings":"","what":"Method sample()","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"Sample values feature(s) conditionally features","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"","code":"ConditionalSampler$sample(feature, data, conditioning_features = NULL)"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"feature (character) Feature name(s) sample (can single multiple) data (data.table ) Data containing conditioning features conditioning_features (character) Features condition (default: features)","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"Modified copy input data feature(s) sampled conditionally","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"","code":"ConditionalSampler$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/ConditionalSampler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Feature Sampler ‚Äî ConditionalSampler","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"Feature Importance Learner Class Feature Importance Learner Class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"label (character(1)) Method label. task (mlr3::Task) learner (mlr3::Learner) measure (mlr3::Measure) resampling (mlr3::Resampling) resample_result (mlr3::ResampleResult) features (character) param_set (paradox::ps()) importance (data.table) Aggregated importance scores scores (data.table) Individual performance scores used compute $importance per resampling iteration permutation iteration.","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"FeatureImportanceMeasure$new() FeatureImportanceMeasure$compute() FeatureImportanceMeasure$combine() FeatureImportanceMeasure$print() FeatureImportanceMeasure$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"Creates new instance R6 class. typically intended use derived classes.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"","code":"FeatureImportanceMeasure$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   param_set = paradox::ps(),   label )"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"task, learner, measure, resampling, features, param_set, label Used set fields","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"Compute feature importance scores","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"","code":"FeatureImportanceMeasure$compute(   relation = c(\"difference\", \"ratio\"),   store_backends = TRUE )"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"relation (character(1): \"difference\") relate perturbed scores originals (\"difference\" \"ratio\") store_backends (logical(1): TRUE) Whether store backends.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"method-combine-","dir":"Reference","previous_headings":"","what":"Method combine()","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"Combine two FeatureImportanceMeasure objects computed scores.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"","code":"FeatureImportanceMeasure$combine(y, ...)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"y (FeatureImportanceMeasure) Object combine. Must computed scores. ... () Unused.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"new FeatureImportanceMeasure subclass x y. Currently method merges following: $scores combined, iter_rsmp increased y. $importance re-computed combined $scores. $resample_result combined mlr3::BenchmarkResult $resampling combined mlr3::ResamplingCustom, continuing te iteration count x y.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"Print importance scores","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"","code":"FeatureImportanceMeasure$print(...)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"... Passed print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"","code":"FeatureImportanceMeasure$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureImportanceMeasure.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Learner Class ‚Äî FeatureImportanceMeasure","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Sampler Class ‚Äî FeatureSampler","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"Base class implementing different sampling strategies feature importance methods like PFI CFI","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"task (mlr3::Task) Original task. label (character(1)) Name sampler.","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"FeatureSampler$new() FeatureSampler$sample() FeatureSampler$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"Creates new instance FeatureSampler class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"","code":"FeatureSampler$new(task)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"task (mlr3::Task) Task sample ","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"method-sample-","dir":"Reference","previous_headings":"","what":"Method sample()","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"Sample values feature(s)","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"","code":"FeatureSampler$sample(feature, data)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"feature (character) Feature name(s) sample (can single multiple) data (data.table ) Data use sampling context","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"Modified copy input data feature(s) sampled","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"","code":"FeatureSampler$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/FeatureSampler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Sampler Class ‚Äî FeatureSampler","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":null,"dir":"Reference","previous_headings":"","what":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"Calculates Leave-One-Covariate-(LOCI) scores. Despite name, implementation can leave one features time.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"LOCI measures feature importance training models individual feature (feature subset) comparing performance featureless baseline model (optimal constant prediction). importance calculated (featureless_model_loss - single_feature_loss). Positive values indicate feature performs better baseline, negative values indicate worse performance.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::LeaveOutIn -> LOCI","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print() xplainfi::LeaveOutIn$compute()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"LOCI$new() LOCI$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"Creates new instance R6 class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"","code":"LOCI$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   iters_refit = 1L )"},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"task (mlr3::Task) Task compute importance . learner (mlr3::Learner) Learner use prediction. measure (mlr3::Measure) Measure use scoring. resampling (mlr3::Resampling) Resampling strategy. Defaults holdout. features (character()) Features compute importance . Defaults features. iters_refit (integer(1)) Number refit iterations per resampling iteration.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"","code":"LOCI$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leave-One-Covariate-In (LOCI) ‚Äî LOCI","text":"","code":"library(mlr3) task = tgen(\"friedman1\")$generate(n = 200) loci = LOCI$new(   task = task,   learner = lrn(\"regr.ranger\", num.trees = 50),   measure = msr(\"regr.mse\") ) loci$compute() #> Key: <feature> #>          feature importance #>           <char>      <num> #>  1:   important1  -2.969393 #>  2:   important2   1.948452 #>  3:   important3  -5.010906 #>  4:   important4   3.429913 #>  5:   important5  -4.165704 #>  6: unimportant1 -14.275524 #>  7: unimportant2  -1.219029 #>  8: unimportant3  -6.348356 #>  9: unimportant4  -2.449776 #> 10: unimportant5  -6.581783"},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":null,"dir":"Reference","previous_headings":"","what":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"Calculates Leave-One-Covariate-(LOCO) scores. Despite name, implementation can leave one features time.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"LOCO measures feature importance comparing model performance without feature. feature, model retrained without feature performance difference (reduced_model_loss - full_model_loss) indicates feature's importance. Higher values indicate important features.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::LeaveOutIn -> LOCO","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print() xplainfi::LeaveOutIn$compute()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"LOCO$new() LOCO$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"Creates new instance R6 class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"","code":"LOCO$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   iters_refit = 1L )"},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"task (mlr3::Task) Task compute importance . learner (mlr3::Learner) Learner use prediction. measure (mlr3::Measure) Measure use scoring. resampling (mlr3::Resampling) Resampling strategy. Defaults holdout. features (character()) Features compute importance . Defaults features. iters_refit (integer(1)) Number refit iterations per resampling iteration.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"","code":"LOCO$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LOCO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leave-One-Covariate-Out (LOCO) ‚Äî LOCO","text":"","code":"library(mlr3) task = tgen(\"friedman1\")$generate(n = 200) loco = LOCO$new(   task = task,   learner = lrn(\"regr.ranger\", num.trees = 50),   measure = msr(\"regr.mse\") ) loco$compute() #> Key: <feature> #>          feature importance #>           <char>      <num> #>  1:   important1  2.7558605 #>  2:   important2  2.9474815 #>  3:   important3 -0.2593870 #>  4:   important4  7.1902828 #>  5:   important5 -0.7590830 #>  6: unimportant1 -0.8809098 #>  7: unimportant2 -0.8694855 #>  8: unimportant3 -1.6012801 #>  9: unimportant4 -1.2069274 #> 10: unimportant5 -1.5892540"},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":null,"dir":"Reference","previous_headings":"","what":"Leave-Out/In Base Class ‚Äî LeaveOutIn","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"Base class Leave-Leave-feature importance methods. abstract class - use LOCO LOCI.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"xplainfi::FeatureImportanceMeasure -> LeaveOutIn","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"direction (character(1)) Either \"leave-\" \"leave-\".","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"LeaveOutIn$new() LeaveOutIn$compute() LeaveOutIn$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"Creates new instance R6 class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"","code":"LeaveOutIn$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   direction,   label,   iters_refit = 1L )"},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"task, learner, measure, resampling, features Passed FeatureImportanceMeasure construction. direction (character(1)) Either \"leave-\" \"leave-\". label (character(1)) Method label. iters_refit (integer(1)) Number refit iterations per resampling iteration.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"Computes leave-leave-feature importance.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"","code":"LeaveOutIn$compute(relation = c(\"difference\", \"ratio\"), store_backends = TRUE)"},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"relation (character(1)) Calculate \"difference\" (default) \"ratio\" original scores scores leaving /features. store_backends (logical(1)) Passed mlr3::resample store backends resample result. Required measures, may increase memory footprint.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"","code":"LeaveOutIn$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/LeaveOutIn.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-Out/In Base Class ‚Äî LeaveOutIn","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal SAGE ‚Äî MarginalSAGE","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"SAGE marginal sampling (features marginalized independently). standard SAGE implementation.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::SAGE -> MarginalSAGE","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print() xplainfi::SAGE$compute()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"MarginalSAGE$new() MarginalSAGE$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"Creates new instance MarginalSAGE class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"","code":"MarginalSAGE$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   n_permutations = 10L,   reference_data = NULL,   max_reference_size = 100L )"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"task, learner, measure, resampling, features Passed SAGE. n_permutations (integer(1)) Number permutations sample. reference_data (data.table) Optional reference dataset. max_reference_size (integer(1)) Maximum size reference dataset.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"","code":"MarginalSAGE$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSAGE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal SAGE ‚Äî MarginalSAGE","text":"","code":"library(mlr3) task = tgen(\"friedman1\")$generate(n = 100) sage = MarginalSAGE$new(   task = task,   learner = lrn(\"regr.ranger\", num.trees = 50),   measure = msr(\"regr.mse\"),   n_permutations = 3L ) sage$compute() #>          feature  importance #>           <char>       <num> #>  1:   important1  4.38863397 #>  2:   important2  4.62074194 #>  3:   important3  0.48564387 #>  4:   important4  5.60324389 #>  5:   important5  2.04396055 #>  6: unimportant1  0.12571219 #>  7: unimportant2  0.10407407 #>  8: unimportant3  0.24336112 #>  9: unimportant4 -0.01952668 #> 10: unimportant5 -0.23468420"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Feature Sampler ‚Äî MarginalSampler","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"Implements marginal sampling PFI, feature interest sampled independently features","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"xplainfi::FeatureSampler -> MarginalSampler","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"MarginalSampler$new() MarginalSampler$sample() MarginalSampler$print() MarginalSampler$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"Creates new instance MarginalSampler class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"","code":"MarginalSampler$new(task)"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"task (mlr3::Task) Task sample ","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"method-sample-","dir":"Reference","previous_headings":"","what":"Method sample()","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"Sample values feature(s) permutation (marginal distribution)","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"","code":"MarginalSampler$sample(feature, data)"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"feature (character) Feature name(s) sample (can single multiple) data (data.table ) Data permute feature(s) ","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"Modified copy input data feature(s) permuted","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"Print sampler","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"","code":"MarginalSampler$print(...)"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"... Passed print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"","code":"MarginalSampler$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/MarginalSampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Feature Sampler ‚Äî MarginalSampler","text":"","code":"library(mlr3) task = tgen(\"2dnormals\")$generate(n = 100) sampler = MarginalSampler$new(task) data = task$data() sampled_data = sampler$sample(\"x1\", data)"},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Permutation Feature Importance ‚Äî PFI","title":"Permutation Feature Importance ‚Äî PFI","text":"Implementation PFI using modular sampling approach","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Permutation Feature Importance ‚Äî PFI","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::PerturbationImportance -> PFI","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Permutation Feature Importance ‚Äî PFI","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Permutation Feature Importance ‚Äî PFI","text":"PFI$new() PFI$compute() PFI$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Permutation Feature Importance ‚Äî PFI","text":"Creates new instance PFI class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation Feature Importance ‚Äî PFI","text":"","code":"PFI$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   iters_perm = 1L )"},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation Feature Importance ‚Äî PFI","text":"task, learner, measure, resampling, features Passed PerturbationImportance iters_perm (integer(1)) Number permutation iterations","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Permutation Feature Importance ‚Äî PFI","text":"Compute PFI scores","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation Feature Importance ‚Äî PFI","text":"","code":"PFI$compute(relation = c(\"difference\", \"ratio\"), store_backends = TRUE)"},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation Feature Importance ‚Äî PFI","text":"relation (character(1)) relate perturbed scores originals store_backends (logical(1)) Whether store backends","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Permutation Feature Importance ‚Äî PFI","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation Feature Importance ‚Äî PFI","text":"","code":"PFI$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation Feature Importance ‚Äî PFI","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permutation Feature Importance ‚Äî PFI","text":"","code":"library(mlr3) task = tgen(\"2dnormals\")$generate(n = 100) pfi = PFI$new(   task = task,   learner = lrn(\"classif.ranger\", num.trees = 50, predict_type = \"prob\"),   measure = msr(\"classif.ce\") ) pfi$compute() #> Key: <feature> #>    feature importance #>     <char>      <num> #> 1:      x1  0.1818182 #> 2:      x2  0.2121212"},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Importance Base Class ‚Äî PerturbationImportance","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"Abstract base class feature importance methods","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"xplainfi::FeatureImportanceMeasure -> PerturbationImportance","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"sampler (FeatureSampler) Sampler object feature perturbation","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$compute() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"PerturbationImportance$new() PerturbationImportance$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"Creates new instance PerturbationImportance class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"","code":"PerturbationImportance$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   sampler = NULL )"},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"task, learner, measure, resampling, features Passed FeatureImportanceMeasure sampler (FeatureSampler) Sampler use feature perturbation","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"","code":"PerturbationImportance$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/PerturbationImportance.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Importance Base Class ‚Äî PerturbationImportance","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative Feature Importance ‚Äî RFI","title":"Relative Feature Importance ‚Äî RFI","text":"Implementation RFI using modular sampling approach","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Relative Feature Importance ‚Äî RFI","text":"K√∂nig, Gunnar, Molnar, Christoph, Bischl, Bernd, Grosse-Wentrup, Moritz (2021). ‚ÄúRelative Feature Importance.‚Äù 2020 25th International Conference Pattern Recognition (ICPR), 9318‚Äì9325. doi:10.1109/ICPR48806.2021.9413090 .","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"super-classes","dir":"Reference","previous_headings":"","what":"Super classes","title":"Relative Feature Importance ‚Äî RFI","text":"xplainfi::FeatureImportanceMeasure -> xplainfi::PerturbationImportance -> RFI","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Relative Feature Importance ‚Äî RFI","text":"conditioning_set (character()) Features condition ","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Relative Feature Importance ‚Äî RFI","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Relative Feature Importance ‚Äî RFI","text":"RFI$new() RFI$compute() RFI$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Relative Feature Importance ‚Äî RFI","text":"Creates new instance RFI class","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Feature Importance ‚Äî RFI","text":"","code":"RFI$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   conditioning_set = NULL,   iters_perm = 1L,   sampler = NULL )"},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Feature Importance ‚Äî RFI","text":"task, learner, measure, resampling, features Passed PerturbationImportance conditioning_set (character()) Set features condition iters_perm (integer(1)) Number permutation iterations sampler (ConditionalSampler) Optional custom sampler. Defaults ARFSampler","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Relative Feature Importance ‚Äî RFI","text":"Compute RFI scores","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Feature Importance ‚Äî RFI","text":"","code":"RFI$compute(relation = c(\"difference\", \"ratio\"), store_backends = TRUE)"},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Feature Importance ‚Äî RFI","text":"relation (character(1)) relate perturbed scores originals store_backends (logical(1)) Whether store backends","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Relative Feature Importance ‚Äî RFI","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Feature Importance ‚Äî RFI","text":"","code":"RFI$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Feature Importance ‚Äî RFI","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/RFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative Feature Importance ‚Äî RFI","text":"","code":"library(mlr3) task = tgen(\"friedman1\")$generate(n = 200) rfi = RFI$new(   task = task,   learner = lrn(\"regr.ranger\", num.trees = 50),   measure = msr(\"regr.mse\"),   conditioning_set = c(\"important1\") ) #> Iteration: 0, Accuracy: 53.3% #> Iteration: 1, Accuracy: 35.01% rfi$compute() #> Key: <feature> #>          feature  importance #>           <char>       <num> #>  1:   important1  0.00000000 #>  2:   important2  5.62948468 #>  3:   important3  0.44096938 #>  4:   important4  9.11749980 #>  5:   important5  3.47544825 #>  6: unimportant1  0.11891909 #>  7: unimportant2 -0.34134400 #>  8: unimportant3  0.61999839 #>  9: unimportant4 -0.25918723 #> 10: unimportant5  0.03659511"},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":null,"dir":"Reference","previous_headings":"","what":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"Base class SAGE (Shapley Additive Global Importance) feature importance based Shapley values marginalization. abstract class - use MarginalSAGE ConditionalSAGE.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"SAGE uses Shapley values fairly distribute total prediction performance among features. Unlike perturbation-based methods, SAGE marginalizes features integrating distribution. approximated averaging predictions reference dataset.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"Covert, ., Lundberg, S. M., & Lee, S. . (2020). Understanding global feature contributions game-theoretic interpretations black-box models. arXiv preprint arXiv:2010.12012.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"xplainfi::FeatureImportanceMeasure -> SAGE","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"n_permutations (integer(1)) Number permutations sample. reference_data (data.table) Reference dataset marginalization. sampler (FeatureSampler) Sampler object marginalization.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"xplainfi::FeatureImportanceMeasure$combine() xplainfi::FeatureImportanceMeasure$print()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"SAGE$new() SAGE$compute() SAGE$clone()","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"Creates new instance SAGE class.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"","code":"SAGE$new(   task,   learner,   measure,   resampling = NULL,   features = NULL,   n_permutations = 10L,   reference_data = NULL,   sampler = NULL,   max_reference_size = 100L )"},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"task, learner, measure, resampling, features Passed FeatureImportanceMeasure. n_permutations (integer(1)) Number permutations sample Shapley value estimation. reference_data (data.table) Optional reference dataset. NULL, uses training data. sampler (FeatureSampler) Sampler marginalization. max_reference_size (integer(1)) Maximum size reference dataset. reference larger, subsampled.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"method-compute-","dir":"Reference","previous_headings":"","what":"Method compute()","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"Compute SAGE values.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"","code":"SAGE$compute(store_backends = TRUE)"},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"store_backends (logical(1)) Whether store backends.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"objects class cloneable method.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"","code":"SAGE$clone(deep = FALSE)"},{"path":"https://jemus42.github.io/xplainfi/reference/SAGE.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shapley Additive Global Importance (SAGE) Base Class ‚Äî SAGE","text":"deep Whether make deep clone.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/c.FeatureImportanceMeasure.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","title":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","text":"Combine two FeatureImportanceMeasure objects","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/c.FeatureImportanceMeasure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","text":"","code":"# S3 method for class 'FeatureImportanceMeasure' c(x, y, ...)"},{"path":"https://jemus42.github.io/xplainfi/reference/c.FeatureImportanceMeasure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","text":"x, y ([FeatureImportanceMeasure]) Objects combine. Must computed scores. ... () Ignored.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/c.FeatureImportanceMeasure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","text":"New object subclass x y.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/c.FeatureImportanceMeasure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine two FeatureImportanceMeasure objects ‚Äî c.FeatureImportanceMeasure","text":"","code":"library(mlr3) task = tgen(\"2dnormals\")$generate(n = 100)  pfi1 = PFI$new(   task = task,   learner = lrn(\"classif.ranger\", num.trees = 50, predict_type = \"prob\"),   measure = msr(\"classif.ce\"),   features = \"x1\" ) pfi1$compute() #> Key: <feature> #>    feature importance #>     <char>      <num> #> 1:      x1  0.1212121  pfi2 = PFI$new(   task = task,   learner = lrn(\"classif.ranger\", num.trees = 50, predict_type = \"prob\"),   measure = msr(\"classif.ce\"),   features = \"x2\" ) pfi2$compute() #> Key: <feature> #>    feature importance #>     <char>      <num> #> 1:      x2  0.1515152  combined = c(pfi1, pfi2)"},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Scoring utility ‚Äî compute_score","title":"Scoring utility ‚Äî compute_score","text":"Computes relation score change (e.g. PFI, LOCO, ...) .","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scoring utility ‚Äî compute_score","text":"","code":"compute_score(   scores_pre,   scores_post,   relation = c(\"difference\", \"ratio\"),   minimize = TRUE )"},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scoring utility ‚Äî compute_score","text":"scores_pre (numeric) Score change. scores_post (numeric) Score change. relation (character(1): \"difference\") Either \"difference\" \"ratio\". \"difference\", scores_post - scores_pre computed, otherwise scores_post / scores_pre. minimize (logical(1), TRUE) Whether score needs minimized (e.g. RMSE) maximized (e.g. AUC).","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scoring utility ‚Äî compute_score","text":"numeric vector length scores_pre scores_post","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scoring utility ‚Äî compute_score","text":"minimize == TRUE, scores_post - scores_pre computed relation == \"difference\", otherwise scores_pre - scores_post given. minimize == FALSE, scores_pre - scores_post computed.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/compute_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scoring utility ‚Äî compute_score","text":"","code":"pre = rnorm(10) post = pre + runif(10)  compute_score(pre, post) #>  [1] 0.3501801 0.3782836 0.1380184 0.4995242 0.3355294 0.7474271 0.1727735 #>  [8] 0.3766082 0.6930425 0.6925969 compute_score(pre, post, \"ratio\") #>  [1]  0.565179226  1.716508216  1.205576681 -0.175535642  0.662399027 #>  [6]  0.485872961  0.478949975  0.001711709 -0.032528370  2.140999602 compute_score(pre, post, minimize = FALSE) #>  [1] -0.3501801 -0.3782836 -0.1380184 -0.4995242 -0.3355294 -0.7474271 #>  [7] -0.1727735 -0.3766082 -0.6930425 -0.6925969"},{"path":"https://jemus42.github.io/xplainfi/reference/op-null-default.html","id":null,"dir":"Reference","previous_headings":"","what":"Default value for NULL ‚Äî op-null-default","title":"Default value for NULL ‚Äî op-null-default","text":"backport %||% available R versions 4.4.0.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/op-null-default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default value for NULL ‚Äî op-null-default","text":"","code":"x %||% y"},{"path":"https://jemus42.github.io/xplainfi/reference/op-null-default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default value for NULL ‚Äî op-null-default","text":"x, y x NULL length 0, return y; otherwise returns x.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/op-null-default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default value for NULL ‚Äî op-null-default","text":"","code":"1 %||% 2 #> [1] 1 NULL %||% 2 #> [1] 2"},{"path":"https://jemus42.github.io/xplainfi/reference/print_bib.html","id":null,"dir":"Reference","previous_headings":"","what":"Print an Rd-formatted bib entry ‚Äî print_bib","title":"Print an Rd-formatted bib entry ‚Äî print_bib","text":"Print Rd-formatted bib entry","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/print_bib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print an Rd-formatted bib entry ‚Äî print_bib","text":"","code":"print_bib(...)"},{"path":"https://jemus42.github.io/xplainfi/reference/print_bib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print an Rd-formatted bib entry ‚Äî print_bib","text":"... (character) One quoted names bibentries print.","code":""},{"path":"https://jemus42.github.io/xplainfi/reference/xplainfi-package.html","id":null,"dir":"Reference","previous_headings":"","what":"xplainfi: Feature Importance Methods for Model Interpretability ‚Äî xplainfi-package","title":"xplainfi: Feature Importance Methods for Model Interpretability ‚Äî xplainfi-package","text":"Provides consistent interface common feature importance methods, permutation feature importance, 'LOCO', 'SAGE'.","code":""},{"path":[]},{"path":"https://jemus42.github.io/xplainfi/reference/xplainfi-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"xplainfi: Feature Importance Methods for Model Interpretability ‚Äî xplainfi-package","text":"Maintainer: Lukas Burk github@quantenbrot.de (ORCID)","code":""},{"path":"https://jemus42.github.io/xplainfi/news/index.html","id":"xplainfi-0009000-development-version","dir":"Changelog","previous_headings":"","what":"xplainfi 0.0.0.9000 (development version)","title":"xplainfi 0.0.0.9000 (development version)","text":"Initial design phase.","code":""}]
